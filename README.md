# Class Activation Maps
***
A technique for making Convolutional Neural Network (CNN)-based models more transparent by visualizing the regions of input that are “important” for predictions from these models — or visual explanations.

## [View apresentation](lectures/activation-class-map.pdf)
![image](https://user-images.githubusercontent.com/58775072/112550690-81fb2080-8d9e-11eb-9f10-8f925e67a8c6.png)

## Examples using images of VinBigData and the Inception architecture

|||
|-|-|
|![image1](images/image4.jpg)|![image2](images/image5.jpg)|
|![image3](images/image6.jpg)|![image4](images/image7.jpg)|



