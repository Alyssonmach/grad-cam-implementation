# Class Activation Maps
***
A technique for making Convolutional Neural Network (CNN)-based models more transparent by visualizing the regions of input that are “important” for predictions from these models — or visual explanations.

Algoritmos de visualização gráfica para redes neurais convolucionais são úteis para entender o que as camadas de convolução estão dando mais destaque em imagens digitais. Particularmente na área médica, esses métodos se mostram eficazes para validar a eficâcia dos modelos criado, já que esses necessitam ser bem arquitetados. Tendo em vista essas observações, dois algoritmos mostraram-se relevantes para essas finalidades, são eles:

- [Grad CAM](https://github.com/Alyssonmach/class-activation-maps/blob/main/lectures/1-activation-class-map.pdf)
- [LIME](https://github.com/Alyssonmach/class-activation-maps/blob/main/lectures/2-lime-algorithm.pdf)

Para maiores esclarecimentos, os slides acima garantem explicações teóricas sobre os dois algoritmos.

### Exemplos de imagens da Grad CAM

|||
|-|-|
|![image5](images/grad-cam/image5.jpg)||[image7](images/grad-cam/image7.jpg)|
|![image2](images/grad-cam/image2.jpg)||[image3](images/grad-cam/image3.jpg)|

### Exemplos de imagens do LIME

![image4](images/lime/image4.png)






